{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd6f233",
   "metadata": {},
   "source": [
    "## MONET-Analysis AERONET prep notebook\n",
    "\n",
    "### How to use\n",
    "\n",
    "- start notebook and \n",
    "- in cell 2 set the start date and end date\n",
    "- in cell 2 set the filename output (something like AERONET_L15_STARTDATE_ENDDATE.nc with STARTDATE and ENDDATE in YYYYMMDD format)\n",
    "- in order to run this notebook, please install pytspack into your conda environment. To do this on the NOAA Hera system, first load gnu (module load gnu). Second install pytspack via pip (pip install --no-deps https://github.com/noaa-oar-arl/pytspack/archive/master.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import monetio as mio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from melodies_monet.util import write_util\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the dates\n",
    "### for some reason the 7th of august 2019 has an error reading in the parallel version.  \n",
    "# Not sure why but some of the dtypes are different when processing in parallel vs serial.  \n",
    "# Here we will use the serial version just to make it easy for everyone to understand.        \n",
    "### For faster processing in other periods add the `n_procs=n` kwarg where n is the number of processes\n",
    "dates = pd.date_range(start='2019-09-01',end='2019-09-30',freq='H')\n",
    "# set the output filename\n",
    "outname = 'AERONET_L15_20190901_20190930.nc'\n",
    "# set standard wavelengths\n",
    "standard_wavelengths = np.array([0.34, 0.44, 0.55, 0.66, 0.86, 1.63, 11.1])* 1000. # convert from micron to nm \n",
    "# get the data \n",
    "df = mio.aeronet.add_data(dates, interp_to_aod_values=standard_wavelengths, freq='H') # ,n_procs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfp = df.rename({'siteid':'x'},axis=1).set_index(['time','x']).drop_duplicates()\n",
    "# df = df3 \n",
    "verbose=False\n",
    "dfp = df.rename({'siteid':'x'},axis=1).set_index(['time','x'])\n",
    "columns = dfp.columns.to_list()\n",
    "columns2 = []\n",
    "remove_columns = []\n",
    "for i in np.arange(len(columns)):\n",
    "    columns2.append(columns[i])\n",
    "    try:\n",
    "        dfp[columns2].to_xarray()\n",
    "        if verbose:\n",
    "            print('COLUMN SUCCESS:',columns[i])\n",
    "    except:\n",
    "        if verbose:\n",
    "            print('COLUMN FAILURE:',columns[i])\n",
    "        remove_columns.append(columns[i])\n",
    "        columns2.remove(columns[i])\n",
    "if verbose:\n",
    "    print(columns2)\n",
    "dft = df.drop(remove_columns,axis=1)\n",
    "dfp = dfp.drop(remove_columns,axis=1).dropna(subset=['latitude','longitude'])\n",
    "dfx = dfp.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = []\n",
    "for s in df.siteid.unique():\n",
    "    dsets.append(dft.loc[df.siteid == s].set_index(['time']).to_xarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e954f7c-31bb-4f17-a6ec-b42a86435402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now site_variable are the single element attributes of the individual site so lets simplify this\n",
    "\n",
    "from numpy import unique\n",
    "site_variable = ['siteid','latitude','longitude','aeronet_instrument_number','elevation']\n",
    "\n",
    "def expand_dims(ds, index=0):\n",
    "    # first set a new index for the siteid\n",
    "    ds['x'] = index\n",
    "    ds = ds.expand_dims(['x'])\n",
    "    ds = ds.set_coords(['x'])\n",
    "    # now reduce the site variables to single element variables \n",
    "    for sv in site_variable:\n",
    "        tmp = [unique(ds[sv])[0]]\n",
    "        ds[sv] = (('x',), tmp)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bb15b2-ac56-4676-91b0-abda0e1e4b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now site_variable are the single element attributes of the individual site so lets simplify this\n",
    "for index,d in enumerate(dsets):\n",
    "    dsets[index] = expand_dims(d,index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae366181-6258-4aac-8520-f234271328f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now combine all the datasets for each site into a single dataset\n",
    "ds = xr.concat(dsets,dim='x').set_coords(site_variable)\n",
    "# ds\n",
    "os.path.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the file \n",
    "t = ds.expand_dims('y').transpose('time','y','x')\n",
    "write_util.write_ncf(t,outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-roller",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7004ca-dbe3-49a0-a220-5d5c85bbd6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61226573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
